model: hf 

model_args: 
  pretrained: allenai/Olmo-3-7B-Instruct
  dtype: bfloat16

apply_chat_template : True 

log_samples: True

output_path: ./results/ 

device: cuda:0 

batch_size: 32

# do_sample does greedy decoding if True
gen_kwargs:
  temperature: 0.7
  top_p: 0.9
  do_sample: True
  max_new_tokens: 2047
  until:
  - "</s>"
  - "<|im_end|>"